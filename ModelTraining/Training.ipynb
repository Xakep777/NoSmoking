# ===============================
# 1. –†–æ–∑–ø–∞–∫—É–≤–∞–Ω–Ω—è –∞—Ä—Ö—ñ–≤—É
# ===============================
#import zipfile
#with zipfile.ZipFile("/content/archive.zip", 'r') as zip_ref:
#    zip_ref.extractall("/content/smoker_data")

# ===============================
# 2. –Ü–º–ø–æ—Ä—Ç–∏
# ===============================
import os
import pandas as pd
from PIL import Image
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models

from tqdm import tqdm
import copy

# ===============================
# 3. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—ñ–≤ –∑ –Ω–∞–∑–≤ —Ñ–∞–π–ª—ñ–≤
# ===============================
def get_dataframe_from_folder(folder_path):
    data = []
    for file in os.listdir(folder_path):
        if file.lower().endswith(('.jpg', '.jpeg', '.png')):
            fname = file.lower()
            if fname.startswith("notsmoking"):
                label = 0
            elif fname.startswith("smoking"):
                label = 1
            else:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ñ–∞–π–ª–∏ –∑ —ñ–Ω—à–∏–º–∏ –Ω–∞–∑–≤–∞–º–∏
            data.append({
                'image_path': os.path.join(folder_path, file),
                'label': label
            })
    return pd.DataFrame(data)

train_df = get_dataframe_from_folder("/content/smoker_data/Training/Training")
val_df = get_dataframe_from_folder("/content/smoker_data/Validation/Validation")
test_df = get_dataframe_from_folder("/content/smoker_data/Testing/Testing")

# ===============================
# 4. Torch Dataset
# ===============================
class SmokerDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.df = dataframe.reset_index(drop=True)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        image = Image.open(self.df.iloc[idx]['image_path']).convert('RGB')
        label = torch.tensor(self.df.iloc[idx]['label'], dtype=torch.float32)
        if self.transform:
            image = self.transform(image)
        return image, label





# ===============================
# 5. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó —Ç–∞ –ª–æ–∞–¥–µ—Ä–∏
# ===============================
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

train_loader = DataLoader(SmokerDataset(train_df, train_transform), batch_size=16, shuffle=True)
val_loader = DataLoader(SmokerDataset(val_df, val_transform), batch_size=16, shuffle=False)
test_loader = DataLoader(SmokerDataset(test_df, val_transform), batch_size=16, shuffle=False)


def check_class_distribution(df, name):
    print(f"\nüìä {name} class distribution:")
    counts = df['label'].value_counts().sort_index()
    for label, count in counts.items():
        cls = "Smoker" if label == 1 else "Non-Smoker"
        print(f"  {cls}: {count}")
    if len(counts) < 2:
        print("‚ö†Ô∏è WARNING: Only one class detected!")
    print("-" * 30)

check_class_distribution(train_df, "Train")
check_class_distribution(val_df, "Validation")
check_class_distribution(test_df, "Test")




# ===============================
# 6. –ú–æ–¥–µ–ª—å: EfficientNetB0
# ===============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.efficientnet_b0(pretrained=True)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)
model = model.to(device)

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# ===============================
# 7. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
# ===============================
def train_model(model, train_loader, val_loader, epochs=10):
    best_acc = 0.0
    best_model_wts = copy.deepcopy(model.state_dict())

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        correct = 0

        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images).squeeze(1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            preds = torch.sigmoid(outputs) > 0.5
            correct += (preds == labels.bool()).sum().item()

        train_acc = correct / len(train_loader.dataset)
        print(f"Train Loss: {total_loss/len(train_loader):.4f} | Train Accuracy: {train_acc:.4f}")

        # Validation
        model.eval()
        correct = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images).squeeze(1)
                preds = torch.sigmoid(outputs) > 0.5
                correct += (preds == labels.bool()).sum().item()

        val_acc = correct / len(val_loader.dataset)
        print(f"Validation Accuracy: {val_acc:.4f}")

        if val_acc > best_acc:
            best_acc = val_acc
            best_model_wts = copy.deepcopy(model.state_dict())
            torch.save(model.state_dict(), "best_model.pt")
            print("‚úÖ Model saved.\n")

    model.load_state_dict(best_model_wts)

# ===============================
# 8. –ó–∞–ø—É—Å–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
# ===============================
train_model(model, train_loader, val_loader, epochs=20)

# ===============================
# 9. –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
# ===============================
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images).squeeze(1)
        preds = torch.sigmoid(outputs) > 0.5
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.numpy())

print("\nüß™ Test Set Evaluation:")
print(classification_report(all_labels, all_preds, target_names=["Non-Smoker", "Smoker"]))

# Confusion matrix
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non-Smoker", "Smoker"], yticklabels=["Non-Smoker", "Smoker"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
